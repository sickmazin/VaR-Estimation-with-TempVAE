# TempVAE: Deep Stochastic Volatility for Value-at-Risk

## 1. Scientific Abstract & Objective

This project implements a **Temporal Variational Autoencoder (TempVAE)** for multivariate financial time series analysis. The core objective is to model the joint distribution of asset returns $R_t$ by inferring a latent stochastic process $Z_t$ that represents unobserved market factors (regimes).

The model optimizes the Evidence Lower Bound (ELBO), balancing reconstruction accuracy against the complexity of the latent dynamics.

---

## 2. Mathematical Framework & Architecture

The model assumes the observed returns $R_{1:T}$ are generated by a latent process $Z_{1:T}$ through an autoregressive structure.

### 2.1. Generative Model (Decoder)
The joint probability factorizes into a **Prior** (transition dynamics) and a **Likelihood** (emission):

$$
p_\theta(R, Z) = \prod_{t=1}^T \underbrace{p_\theta(Z_t \mid Z_{1:t-1})}_{\text{Prior}} \cdot \underbrace{p_\theta(R_t \mid Z_{1:t})}_{\text{Likelihood}}
$$

1.  **Prior (Latent Dynamics):** $Z_t$ depends on the history of latent states via a Recurrent Neural Network ($\text{RNN}^z$). 
    $$Z_t \mid Z_{1:t-1} \sim \mathcal{N}(\mu^z_t, \Sigma^z_t)$$
    *Note: The prior is often kept fixed (non-trainable) to enforce stable regularization.*

2.  **Likelihood (Emission):** The return $R_t$ depends on the sequence of latent factors up to time $t$ ($Z_{1:t}$), propagated by a second RNN ($\text{RNN}^r$). 
    $$R_t \mid Z_{1:t} \sim \mathcal{N}(\mu^r_t, \Sigma^r_t)$$
    *Covariance Structure:* Uses a **Rank-1 perturbation** output for $\Sigma^r$ to model asset correlations efficiently.

### 2.2. Inference Model (Encoder)
We approximate the posterior with $q_\phi$, conditioning on the **entire** observation sequence $R_{1:T}$ using a Bidirectional GRU:

$$q_\phi(Z \mid R) = \prod_{t=1}^T q_\phi(Z_t \mid Z_{1:t-1}, R_{1:T})$$

The architecture integrates global context as follows:

$$ \hat{h}^z_t = \text{RNN}_I^z (\hat{h}^z_{t-1}, Z_{t-1}, [\hat{h}^{\rightarrow}_t, \hat{h}^{\leftarrow}_t]) $$

Where $[
\hat{h}^{\rightarrow}_t, \hat{h}^{\leftarrow}_t]$ are the concatenated forward and backward states of the Bi-GRU processing $R$.

---

## 3. Paper Replication: "Estimating the Value-at-Risk by Temporal VAE"

This repository replicates the methodology from **"Estimating the Value-at-Risk by Temporal VAE"** (`paper/EstimatingVaR_TempVAE.pdf`).

### Implementation Details
*   **Latent Dim**: 10.
*   **Hidden Layers**: 16 units (RNNs and MLPs).
*   **Initialization**: He (Variance Scaling).
*   **Regularization**: L2 ($\lambda=0.01$) on MLP weights, Dropout ($10\%$) on RNNs.

### Benchmarks (`final_data/paper_run_result`)
*   **`var_series.png`**: VaR predictions under volatile regimes.
*   **`latent_manifold.png`**: Clustering of market states in the latent space.
*   **`active_units.png`**: Verification of "Active Units" via KL-Divergence.

---

## 4. Project Structure & File Roles

### üß† Model Architecture
*   **`TempVae.py`**: **THE MODEL**. Defines the `TempVAE` class architecture, including the Bi-GRU Encoder and the Autoregressive Decoder.

### ‚öôÔ∏è Execution & Data
*   **`main.py`**: **ENTRY POINT (Training)**. Primary script for training and full analysis. Includes the `FinancialDataset` class and the `CONFIG` dictionary.
*   **`inference_comparison.py`**: **INFERENCE ENGINE**. Use this script to load a pre-trained `best_model.pth` and perform backtesting/comparisons without training the network again.

### üî¨ Research & Replication
*   **`paper_exact_replication.py`**: **BENCHMARK SCRIPT**. Specialized for reproducing the results of the paper using fixed seeds and specific initialization schemes.

### üõ† Utilities
*   **`inference_utils.py`**: Post-training tools for VaR calculation and distribution sampling.
*   **`visualize_graph.py`**: Utility to visualize the neural network architecture graph.

---

## 5. Setup & Usage

### Installation
```bash
pip install -r requirements.txt
```

### Option A: Train from Scratch
To train the model and generate a new `best_model.pth`:
```bash
python main.py
```

### Option B: Run Inference (Using Saved Weights)
To perform analysis using the already trained model:
```bash
python inference_comparison.py
```
*This script loads the weights (e.g., from `final_data/paper_run_result/best_model.pth`), sets the model to `eval()` mode, and executes the backtesting pipeline.*

---

*Author: Mattia